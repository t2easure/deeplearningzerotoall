{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfab3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c11fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051df226",
   "metadata": {},
   "source": [
    "# MNIST 데이터셋\n",
    "손으로 쓰여진 숫자 데이터셋 (handwritten digits dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dc49d",
   "metadata": {},
   "source": [
    "- 28 x 28 해상도의 이미지 \n",
    "- 1 channel gray image (gray scale 이미지)\n",
    "- 0 ~ 9 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543327f0",
   "metadata": {},
   "source": [
    "### torchvision\n",
    "pytorch에서 사용하는 패키지 중 하나. \n",
    "- MNIST, Fashion-MNIST 등의 데이터와 VGG, ResNet등의 모델들, transforms, utils 가 들어있는 굉장히 유용한 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ecf567",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705f081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb11573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:03<00:00, 2.91MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 143kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd1301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3d666",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "- epoch : training set 전체가 한 번 학습에 사용되면 1 에폭이 돌았다고 표현.\n",
    "- batch size : 한 에폭을 한번에 학습하기엔 메모리 부족으로 잘라서 사용하는데, 이 때 자르는 크기.\n",
    "- iterations : 배치를 몇 번 학습에 사용했는지. (트레이닝 셋 크기 / 배치 사이즈)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b846a4",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeaa933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 15, Cost: 0.306538\n",
      "Epoch: 1 / 15, Cost: 0.365260\n",
      "Epoch: 2 / 15, Cost: 0.363365\n",
      "Epoch: 3 / 15, Cost: 0.304113\n",
      "Epoch: 4 / 15, Cost: 0.445962\n",
      "Epoch: 5 / 15, Cost: 0.256751\n",
      "Epoch: 6 / 15, Cost: 0.227891\n",
      "Epoch: 7 / 15, Cost: 0.373778\n",
      "Epoch: 8 / 15, Cost: 0.259989\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "# MNIST가 0-9 의 라벨을 가지기에 10.\n",
    "linear = torch.nn.Linear(28 * 28, 10, bias=True).to(device)\n",
    "\n",
    "# parameters\n",
    "trainig_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(trainig_epochs + 1):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 784).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    print(\"Epoch: {} / {}, Cost: {:4f}\".format(epoch, trainig_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 계산하지 않기 (test)\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
