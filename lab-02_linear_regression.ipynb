{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bb11dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af29cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742f81ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b3a34023d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bfd9d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac583bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00de3d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d318a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba11977",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "requires_grad : True여야만 학습할 수 있음. (미분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e398d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "print(W)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775b02e",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "H(x) = Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b576a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98187b30",
   "metadata": {},
   "source": [
    "## Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2782d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "tensor([[-1.],\n",
      "        [-2.],\n",
      "        [-3.]], grad_fn=<SubBackward0>)\n",
      "tensor([[1.],\n",
      "        [4.],\n",
      "        [9.]], grad_fn=<PowBackward0>)\n",
      "tensor(4.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)\n",
    "print(hypothesis - y_train)\n",
    "print((hypothesis - y_train) ** 2)\n",
    "\n",
    "# MSE loss \n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1a265",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10bbf38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0933], requires_grad=True)\n",
      "tensor([0.0400], requires_grad=True)\n",
      "tensor([[0.1333],\n",
      "        [0.2267],\n",
      "        [0.3200]], grad_fn=<AddBackward0>)\n",
      "tensor(3.6927, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "optimizer.zero_grad\n",
    "cost.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)\n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f26502",
   "metadata": {},
   "source": [
    "## Training with Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda73fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
      "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
      "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
      "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
      "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
      "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
      "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
      "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
      "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
      "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
      "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = W * x_train + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523cadc7",
   "metadata": {},
   "source": [
    "## High-level 구현\n",
    "nn.Module 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b376be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fad19",
   "metadata": {},
   "source": [
    "linear regression 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a099a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor '__init__' of 'super' object needs an argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegressionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mLinearRegressionModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: descriptor '__init__' of 'super' object needs an argument"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03da89",
   "metadata": {},
   "source": [
    "hypothesis : y = wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(x_train)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d88ed5",
   "metadata": {},
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)\n",
    "\n",
    "cost = F.mse_loss(hypothesis, y_train)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a6995",
   "metadata": {},
   "source": [
    "gradient descent \n",
    ": PyTorch의 torch.optim에 있는 optimizer 중 하나 사용 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e0271",
   "metadata": {},
   "source": [
    "full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f49a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f}, Cost: {:.6f}'.format(epoch, nb_epochs, W, b, cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
